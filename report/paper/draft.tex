\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024
\PassOptionsToPackage{numbers, compress}{natbib}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
\usepackage[final]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}       % graphics (added by Jeffery)
\usepackage{float}          % float (added by Jeffery)

\title{ UMD Building Classification }

\author{%
  Can Li \\
  \texttt{c5405@umd.edu} \\
  \And 
  Jeffery Tian \\
  \texttt{jtian12@umd.edu} \\
  \And 
  Jerry Li\\
  \texttt{jli103@umd.edu} \\
  \And 
  Christopher Lim \\
  \texttt{clim0326@umd.edu} \\
  \And 
  Justin Zhao \\
  \texttt{justinfz@umd.edu} \\
}


\begin{document}


\maketitle


\begin{abstract}
  We propose that, given an input image of a UMD building, we can classify the building with the correct name in close to realtime using CNN image segmentation and classification methods. What makes this project valuable for educational purposes is that we will explore how to build our image database from scratch, experiment with different convolution neural networks, different ways to visualize the CNN layers for debugging our network design and potentially even for segmentation, and utilizing semi-supervised learning.
\end{abstract}


\section{Motivation}
\label{motivation}

Although not addressing an urgent problem, our goal was to gain experience with the entire deep learning lifecycle, from data acquisition to final model evaluation. We built our own image database from scratch and conducted extensive experiments with a variety of supervised and semi-supervised learning models to ensure the highest accuracy.

The challenge came from the fact that we had to build our own dataset from scratch. We additionally worked with implementation of high resolution images on limited datasets to semi-supervised methods, along with the use of Grad-CAM and Score-CAM for image segmentation.

We additionally did experiments on GNNs and HITL with Grad-CAM.

\subsection{Related Works}

Much work has been done with relation to image segmentation of multiple relevant objects (eg. buildings) and their classification.

\begin{itemize}
    \item On the topic of image recognition/classification, AlexNet, VGG, and Resnet\cite{krizhevsky}\cite{simonyan}\cite{he} are strong examples of fully supervised traditional CNN recognition and classification models. 
    \item With respect to image segmentation, we end up using Grad-CAM/Score-CAM as detailed after this section.
\end{itemize}

This also includes significant work being done on visual explanations of CNN models via Selvaraju, et al.\cite{selvaraju} (2019) Grad-CAM and other related works. These can be used as an alternative method of segmentation and recognition. Below we discuss the main works of relevance to our work:

We prioritized utilizing Semi-Supervised Methods of image recognition. For this, we used FixMatch and MeanTeach methods. 

\begin{itemize}
    \item FixMatch, Sohn, et al.\cite{sohn} (2020), is a semi-supervised learning method that generates “pseudo-labels” using model predictions on weakly augmented unlabeled data, retained only if it’s high confidence; then, train to predict that pseudo label with a strongly augmented version.

    This is a strong method for semi-supervised learning with limited datasets, so will be one of our main driving methods of implementation.
    \item MeanTeacher, Tarvainen, et al.\cite{tarvainen} (2017), is a semi-supervised learning method that uses a teacher model to provide a consistent target for the student model. The teacher model is an exponential moving average of the student model, and the student model is trained to match the teacher model’s predictions.

    At each training step, introduce the same minibatch with random augmentation to separate them. Note that this requires noise in the model. 

    This method can be used to improve the performance of the model, especially when the dataset is relatively small, as in ours
\end{itemize}

% Write: how gradcam can help find the location of the building in the image (to help find its not on the foreground images), point out how this isn't the case in prelim

\begin{itemize} % IP: Gradcam, Scorecam, Gradcam++
    \item Grad-CAM, Selvaraju, et al.\cite{selvaraju} (2019), uses the final gradient into the last convolution layer to produce a visual representation of strength in decision making. This is a visual indicator of model strength and is on paper highly useful for highlighting image classification confidence, but can also be used to help define segmentation. 
    % https://arxiv.org/abs/1610.02391 gradcam
    \item Grad-CAM++, Chattopadhay, et al.\cite{chattopadhay} (2018) is an upgrade to Grad-CAM by generalizing it. It can then isolate/identify multiple object instances in a single image (important for our proposal due to the presence of multiple buildings in images) and a generally improved visual indicator. 
    % https://arxiv.org/abs/1710.11063 gradcam++
    \item Score-CAM, Wang, et al.\cite{wang} (2020) is an alternative approach to Grad-CAM that completely discards using the gradient and instead evaluates the weight of each activation map in the forward pass. 
    % https://arxiv.org/abs/1910.01279 scorecam
\end{itemize}

Grad-CAM++ and Score-CAM can both be used as an important means for highlighting image classification confidence, both of which we intend to use as the most advanced methods in their respective lineages. As an example, see our preliminary original Grad-CAM results in Figure 1 on instances on our test set, where Grad-CAM indicates it's making predictions based on unrelated objects (foreground foliage, people, unrelated elements of the building). This can be used for confirmation of model confidence. If the model is sufficiently confident, this can even be used as a means to indicate building locations (especially given Grad-CAM++ ability to find multiple instances) within the image rather than using traditional segmentation techniques.

Figure 2 (attached to the appendix) has examples utilizing Grad-CAM++ on architecture similar to ResNet.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.3\linewidth]{fig1.png}
    \caption{Preliminary Grad-CAM results example}
    \label{fig:prelim_results_1}
\end{figure}

We additionally used GNN methods and HITL methods. \begin{itemize}
    \item Graph Neural Networks are a method of using graph data to make predictions. This can be used to make predictions on the labeled/unlabeled samples as nodes, and should this perform reasonably this can be used as a primary paradigm as well. 
    
    The main motivator for this is that nodes can be connected by edges to represent relationships that go beyond stride.

    Long et al.\cite{long} (2020) is prior work on GNN image recognition, done on the MNIST dataset on low resolution black and white images. Our intention is to innovate by extending this to high resolution color images of buildings.

    \item Superpixels are a method of dividing an image into regions of similar color. This can be used to help segment the image and can be used to help the model focus on the building itself. This is a method of image segmentation that can be used to help the model focus on the building itself. For graphs, this is a method of reducing the complexity greatly. 

    The SLIC-Superpixel transform, developed by EPFL labs \cite{epflSLICSuperpixels}, is a strong method of superpixel generation that can be used to help segment the image. This can be used to focus node complexity on details.
    \item HITL is human corrections on the network to help the network focus on areas of interest by providing absolute feedback on whether or not Grad-CAM is focusing on the correct areas.
\end{itemize}

\subsection{Motivation for Methods}

From these prior works we have the basic motivation of leveraging traditional CNN image segmentation and recognition techniques for the sake of identifying any buildings in the input images. Our main innovation is to attempt to use Grad-CAM++ or a similar technique to see if they can be used for image segmentation instead, and to attempt to apply this basic system to a variety of goals.

The focus is to see if we can get Grad-CAM to focus on the elements of the image that are important, to help "guide" the model to focus on the building itself. This is important because the model may be making predictions based on unrelated objects in the image, and this can be used to confirm model confidence.

\section{Approach}
\label{approach}

\subsection{Data Collection}

All data will be collected by group members individually. We plan to select a set of UMD buildings (at least 10-15) for the classification. Each building will have at least 50 images taken using our phones from different angles, distances, and lighting (eg. time of day). We plan to do data augmentation for the buildings. 

Preprocessing will be done to normalize/resize images to a standard, strip metadata, and we will also consider color segmenting the building out of the image (eg. filtering out possible noise from the sky/foreground, although this will have the detriment of making it less robust). We also consider using alternative encodings; HSV may help given the UMD red-brown brick style

Should the dataset be large, it can be proposed to train multiple models and utilize model averaging/ensemble voting to merge.

\subsection{Paradigm}

We intend to use a CNN architecture, loosely based around existing methods, in a semi-supervised format. We can use MeanTeacher or FixMatch for the method of semi-supervised learning.

It's also possible to use a graph based method and a GNN. It would be interesting to attempt this by using labeled/unlabled samples as nodes, and should this perform reasonably this can be used as a primary paradigm as well.

Training can be done on Google Colab, but we also have the option of using a training server (SAIL @ Columbia)

\section{Expected Plan}
\label{plan}

\subsection{Timeline}

\begin{enumerate}
    \item Nov 1 - We intend to have the dataset ready. At the time of writing we have \verb|~|1k photos before augmentation and processing.
    \item Mid Nov - We want to ensure we have image classification trained correctly on building recognition for simple cases (single buildings with noise and on various conditions). 
    \item End Nov - Hyper parameter tuning/Grad-CAM++/Score-CAM visualizations to improve the performance of the CNN architecture. Ensure via Grad-CAM that the model is confident and attempt preliminary segmentation on multiple instances and find confidence.
    \item December - Utilize alternative segmentation methods (Grad-CAM/Score-CAM lineage) and alternative architecture (GNNs) and compare with our results.
\end{enumerate}

Note - preliminary results indicate that Score-CAM may be too slow to be ideal on our set.

% chronological plans

\subsection{Moonshot Goals}

% Show a 3D version of the UMD building given by a 2D image as input.
% Take all images of all UMD buildings, including the building interiors, for classification.
% Based on our database of images, generate an image that represents UMD building styles using diffusion models.
% video?\

We have a variety of higher level goals for our project beyond just the basic plan. \begin{itemize}
    \item First, should our model performance be tuned to be sufficiently fast, we would like to be able to apply it to videos. Sampling a video at 5-10 fps and passing it through the video is a simple way to accomplish this given enough performance.
    \item Being able to classify all buildings on UMD (there are a lot of them) rather than just those in the central dataset. 
    \item Being able to identify architectural styles beyond just building names. If the model is sufficiently confident we could even write a model to generate representative images of UMD architecture using a diffusion model (a long shot because it requires massive architecture changes)
    \item Reconstruct a 3-D model of the building using a 2-D model as input (eg. not just classification but an understanding of what the building actually looks like - this is a long shot because it would likely require a lot of data and huge paradigm changes)
    \item Interior identification of buildings (much harder due to a potential lack of distinguishing features)
\end{itemize}

\newpage 
\appendix

\section{Extra Figures}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{fig2.png}
    \caption{Preliminary Results with structure from ResNet}
    \label{fig:prelim_results_2}
\end{figure}

\medskip


\small

\bibliographystyle{abbrv}
\bibliography{sources}

% https://www.getbibtex.com

\end{document}