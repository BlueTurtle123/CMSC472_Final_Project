\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024
\PassOptionsToPackage{numbers, compress}{natbib}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
\usepackage[final]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}       % graphics (added by Jeffery)
\usepackage{float}          % float (added by Jeffery)

\title{ UMD Building Classification }

\author{%
  Can Li \\
  \texttt{c5405@umd.edu} \\
  \And 
  Jeffery Tian \\
  \texttt{jtian12@umd.edu} \\
  \And 
  Jerry Li\\
  \texttt{jli103@umd.edu} \\
  \And 
  Christopher Lim \\
  \texttt{clim0326@umd.edu} \\
  \And 
  Justin Zhao \\
  \texttt{justinfz@umd.edu} \\
}


\begin{document}


\maketitle


\begin{abstract}
  We propose that, given an input image of a UMD building, we can classify the building with the correct name in close to realtime using CNN image segmentation and classification methods. What makes this project valuable for educational purposes is that we will explore how to build our image database from scratch, experiment with different convolution neural networks, different ways to visualize the CNN layers for debugging our network design and potentially even for segmentation, and utilizing semi-supervised learning.
\end{abstract}


\section{Motivation}
\label{motivation}

Although not addressing an urgent problem, our goal was to gain experience with the entire deep learning lifecycle, from data acquisition to final model evaluation. We built our own image database from scratch and conducted extensive experiments with a variety of supervised and semi-supervised learning models to ensure the highest accuracy.

The challenge came from the fact that we had to build our own dataset from scratch. We additionally worked with implementation of high resolution images on limited datasets to semi-supervised methods, along with the use of Grad-CAM and Score-CAM for image segmentation.

We additionally did experiments on GNNs and HITL with Grad-CAM.

\subsection{Related Works}

Much work has been done with relation to image segmentation of multiple relevant objects (eg. buildings) and their classification.

\begin{itemize}
    \item On the topic of image recognition/classification, AlexNet, VGG, and Resnet\cite{krizhevsky}\cite{simonyan}\cite{he} are strong examples of fully supervised traditional CNN recognition and classification models. 
    \item With respect to image segmentation, we end up using Grad-CAM/Score-CAM as detailed after this section.
\end{itemize}

This also includes significant work being done on visual explanations of CNN models via Selvaraju, et al.\cite{selvaraju} (2019) Grad-CAM and other related works. These can be used as an alternative method of segmentation and recognition. Below we discuss the main works of relevance to our work:

We prioritized utilizing Semi-Supervised Methods of image recognition. For this, we used FixMatch and MeanTeach methods. 

\begin{itemize}
    \item FixMatch, Sohn, et al.\cite{sohn} (2020), is a semi-supervised learning method that generates “pseudo-labels” using model predictions on weakly augmented unlabeled data, retained only if it’s high confidence; then, train to predict that pseudo label with a strongly augmented version.

    This is a strong method for semi-supervised learning with limited datasets, so will be one of our main driving methods of implementation.
    \item MeanTeacher, Tarvainen, et al.\cite{tarvainen} (2017), is a semi-supervised learning method that uses a teacher model to provide a consistent target for the student model. The teacher model is an exponential moving average of the student model, and the student model is trained to match the teacher model’s predictions.

    At each training step, introduce the same minibatch with random augmentation to separate them. Note that this requires noise in the model. 

    This method can be used to improve the performance of the model, especially when the dataset is relatively small, as in ours
\end{itemize}

% Write: how gradcam can help find the location of the building in the image (to help find its not on the foreground images), point out how this isn't the case in prelim

\begin{itemize} % IP: Gradcam, Scorecam, Gradcam++
    \item Grad-CAM, Selvaraju, et al.\cite{selvaraju} (2019), uses the final gradient into the last convolution layer to produce a visual representation of strength in decision making. This is a visual indicator of model strength and is on paper highly useful for highlighting image classification confidence, but can also be used to help define segmentation. 
    % https://arxiv.org/abs/1610.02391 gradcam
    \item Grad-CAM++, Chattopadhay, et al.\cite{chattopadhay} (2018) is an upgrade to Grad-CAM by generalizing it. It can then isolate/identify multiple object instances in a single image (important for our proposal due to the presence of multiple buildings in images) and a generally improved visual indicator. 
    % https://arxiv.org/abs/1710.11063 gradcam++
    \item Score-CAM, Wang, et al.\cite{wang} (2020) is an alternative approach to Grad-CAM that completely discards using the gradient and instead evaluates the weight of each activation map in the forward pass. 
    % https://arxiv.org/abs/1910.01279 scorecam
\end{itemize}

Grad-CAM++ and Score-CAM can both be used as an important means for highlighting image classification confidence, both of which we intend to use as the most advanced methods in their respective lineages. As an example, see our preliminary original Grad-CAM results in Figure 1 on instances on our test set, where Grad-CAM indicates it's making predictions based on unrelated objects (foreground foliage, people, unrelated elements of the building). This can be used for confirmation of model confidence. If the model is sufficiently confident, this can even be used as a means to indicate building locations (especially given Grad-CAM++ ability to find multiple instances) within the image rather than using traditional segmentation techniques.

Figure 2 (attached to the appendix) has examples utilizing Grad-CAM++ on architecture similar to ResNet.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.3\linewidth]{fig1.png}
    \caption{Preliminary Grad-CAM results example}
    \label{fig:prelim_results_1}
\end{figure}

We additionally used GNN methods and HITL methods. \begin{itemize}
    \item Graph Neural Networks are a method of using graph data to make predictions. This can be used to make predictions on the labeled/unlabeled samples as nodes, and should this perform reasonably this can be used as a primary paradigm as well. 
    
    The main motivator for this is that nodes can be connected by edges to represent relationships that go beyond stride.

    Long et al.\cite{long} (2020) is prior work on GNN image recognition, done on the MNIST dataset on low resolution black and white images. Our intention is to innovate by extending this to high resolution color images of buildings.

    \item Superpixels are a method of dividing an image into regions of similar color. This can be used to help segment the image and can be used to help the model focus on the building itself. This is a method of image segmentation that can be used to help the model focus on the building itself. For graphs, this is a method of reducing the complexity greatly. 

    The SLIC-Superpixel transform, developed by EPFL labs \cite{epflSLICSuperpixels}, is a method of superpixel generation that can be used to help segment the image. This can be used to focus node complexity on details.
    \item HITL is human corrections on the network to help the network focus on areas of interest by providing absolute feedback on whether or not Grad-CAM is focusing on the correct areas.
\end{itemize}

\subsection{Motivation for Methods}

From these prior works we have the basic motivation of leveraging traditional CNN image segmentation and recognition techniques for the sake of identifying any buildings in the input images. Our main innovation is to attempt to use Grad-CAM++ or a similar technique to see if they can be used for image segmentation instead, and to attempt to apply this basic system to a variety of goals.

The focus is to see if we can get Grad-CAM to focus on the elements of the image that are important, to help "guide" the model to focus on the building itself. This is important because the model may be making predictions based on unrelated objects in the image, and this can be used to confirm model confidence.

\section{Methods}
\label{method}

\subsection{Data Collection}

Data was collected by individually taking pictures and labeling them, along with data augmentation. We took around 4000 photos of UMD buildings over 20 classes, aiming for a 60/40 split of daytime/nighttime photos.

Care was taken to ensure that the photos were taken from a variety of angles and distances. We were limited in time and season since data collection occurred mainly over the course of 2 weeks in fall. 

The dataset was split 80/10/10 for training/validation/testing. Photos were augmented by displacement and inherently varied by rotation. All images were resized to 224x224 for training. 

Test images were further augmented by adding noise and other transforms, including the SyRA synthesized rain (Choi et al. \cite{choi}) method to add rain streaks to the images. 

\subsection{Fully Supervised Baseline}

A fully supervised model was implemented using various ResNet/VGG models for the sake of both comparison and as a baseline for our semi-supervised methods. After training ResNet18 was determined to be best with a 97\% accuracy on test set after %%TODO: fill in

\subsection{Semi-Supervised Methods}

\subsubsection{Grad-CAM/Score-CAM}

\subsubsection{Fixmatch}

\subsubsection{MeanTeacher}

\subsection{GNNs/HITL/VQA Experiments}

% results for these will go into appendix

\subsubsection{GNNs}

\subsubsection{HITL}

\subsubsection{VQA}

\section{Results}
\label{result}

\subsection{Code}

Code for models, data collection and augmentation, along with the SLIC methods and HITL methods, were written and implemented in pytorch and can be found on our Github repository: \url{https://github.com/BlueTurtle123/CMSC472_Final_Project}

\subsection{Fully Supervised Baseline}

% Demonstrate stats

\subsection{Semi-Supervised Methods}

% Demonstrate stats

\subsection{Other Experiments}

\subsubsection{HITL}

\subsubsection{GNN SLIC Transform}

% quick overview of new transform and then note results in appendix

\subsubsection{VQA}

% quick overview of VQA and then note results in appendix

\newpage 
\appendix

\section{Extra Figures}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{fig2.png}
    \caption{Preliminary Results with structure from ResNet}
    \label{fig:prelim_results_2}
\end{figure}

\medskip


\small

\bibliographystyle{abbrv}
\bibliography{sources}

% https://www.getbibtex.com

\end{document}