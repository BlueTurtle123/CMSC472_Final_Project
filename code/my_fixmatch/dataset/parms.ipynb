{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    CLASSES = [\"art_sociology\", \"atlantic\", \"brendan_iribe_center\", \"denton\", \"elkton\", \\\n",
    "                \"ellicott\", \"esj\", \"farm_building\", \"hagerstown\", \"james_clark\", \\\n",
    "                \"laplata\", \"manufacture\", \"mckeldinlib\", \"oakland\", \"physics\", \\\n",
    "                \"prince_frederick\", \"reckord_armory\", \"recreation\", \"regents_drive\", \"yahentamitsi\"]\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\", 0)\n",
    "    NUM_WORKERS = 16 # {2, 4, 8, 16, ...} Depends on the system's CPU\n",
    "    \n",
    "    PATH = './photos'\n",
    "    \n",
    "    BATCH_SIZE = 2**4\n",
    "    \n",
    "    TOTAL_STEPS = 2**12 # number of total steps to run\n",
    "    EVAL_STEPS = 2**5 # number of eval steps to run\n",
    "    EPOCHS = math.ceil(TOTAL_STEPS / EVAL_STEPS)\n",
    "    \n",
    "    LR = 0.01\n",
    "    WEIGHT_DECAY = 5e-4\n",
    "    MOMENTUM = 0.99\n",
    "    \n",
    "    WARM_UP = 0 # warmup epochs (unlabeled data based)\n",
    "    \n",
    "    EMA_DECAY = 0.999 # EMA decay rate\n",
    "    \n",
    "    # Hyper-param for wideresnet\n",
    "    WIDERESNET_DEPTH = 16\n",
    "    WIDERESNET_WIDEN_FACTOR=2\n",
    "    WIDERESNET_DROPOUT=1\n",
    "    \n",
    "    MU = 3 # coefficient of unlabeled batch size\n",
    "    LAMBDA_U = 1 # coefficient of unlabeled loss\n",
    "    \n",
    "    THRESHOLD = 0.95 # pseudo label threshold\n",
    "    T = 1 # pseudo label temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "class Config:\n",
    "    CLASSES = [\"art_sociology\", \"atlantic\", \"brendan_iribe_center\", \"denton\", \"elkton\", \\\n",
    "                \"ellicott\", \"esj\", \"farm_building\", \"hagerstown\", \"james_clark\", \\\n",
    "                \"laplata\", \"manufacture\", \"mckeldinlib\", \"oakland\", \"physics\", \\\n",
    "                \"prince_frederick\", \"reckord_armory\", \"recreation\", \"regents_drive\", \"yahentamitsi\"]\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\", 0)\n",
    "    NUM_WORKERS = 16 # {2, 4, 8, 16, ...} Depends on the system's CPU\n",
    "    \n",
    "    PATH = './photos'\n",
    "    \n",
    "    BATCH_SIZE = 2**4\n",
    "    \n",
    "    TOTAL_STEPS = 2**12 # number of total steps to run\n",
    "    EVAL_STEPS = 2**5 # number of eval steps to run\n",
    "    EPOCHS = math.ceil(TOTAL_STEPS / EVAL_STEPS)\n",
    "    \n",
    "    LR = 0.0020\n",
    "    WEIGHT_DECAY = 5e-4\n",
    "    MOMENTUM = 0.99\n",
    "    \n",
    "    WARM_UP = 0 # warmup epochs (unlabeled data based)\n",
    "    \n",
    "    EMA_DECAY = 0.999 # EMA decay rate\n",
    "    \n",
    "    # Hyper-param for wideresnet\n",
    "    WIDERESNET_DEPTH = 16\n",
    "    WIDERESNET_WIDEN_FACTOR=2\n",
    "    WIDERESNET_DROPOUT=1\n",
    "    \n",
    "    MU = 3 # coefficient of unlabeled batch size\n",
    "    LAMBDA_U = 1 # coefficient of unlabeled loss\n",
    "    \n",
    "    THRESHOLD = 0.95 # pseudo label threshold\n",
    "    T = 1 # pseudo label temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "class Config:\n",
    "    CLASSES = [\"art_sociology\", \"atlantic\", \"brendan_iribe_center\", \"denton\", \"elkton\", \\\n",
    "                \"ellicott\", \"esj\", \"farm_building\", \"hagerstown\", \"james_clark\", \\\n",
    "                \"laplata\", \"manufacture\", \"mckeldinlib\", \"oakland\", \"physics\", \\\n",
    "                \"prince_frederick\", \"reckord_armory\", \"recreation\", \"regents_drive\", \"yahentamitsi\"]\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\", 0)\n",
    "    NUM_WORKERS = 16 # {2, 4, 8, 16, ...} Depends on the system's CPU\n",
    "    \n",
    "    PATH = './photos'\n",
    "    \n",
    "    BATCH_SIZE = 2**4\n",
    "    \n",
    "    TOTAL_STEPS = 2**15 # number of total steps to run\n",
    "    EVAL_STEPS = 2**10 # number of eval steps to run\n",
    "    EPOCHS = math.ceil(TOTAL_STEPS / EVAL_STEPS)\n",
    "    \n",
    "    LR = 0.001\n",
    "    WEIGHT_DECAY = 5e-4\n",
    "    MOMENTUM = 0.99\n",
    "    \n",
    "    WARM_UP = 0 # warmup epochs (unlabeled data based)\n",
    "    \n",
    "    EMA_DECAY = 0.999 # EMA decay rate\n",
    "    \n",
    "    # Hyper-param for wideresnet\n",
    "    WIDERESNET_DEPTH = 16\n",
    "    WIDERESNET_WIDEN_FACTOR=2\n",
    "    WIDERESNET_DROPOUT=1\n",
    "    \n",
    "    MU = 3 # coefficient of unlabeled batch size\n",
    "    LAMBDA_U = 1 # coefficient of unlabeled loss\n",
    "    \n",
    "    THRESHOLD = 0.95 # pseudo label threshold\n",
    "    T = 1 # pseudo label temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "class Config:\n",
    "    CLASSES = [\"art_sociology\", \"atlantic\", \"brendan_iribe_center\", \"denton\", \"elkton\", \\\n",
    "                \"ellicott\", \"esj\", \"farm_building\", \"hagerstown\", \"james_clark\", \\\n",
    "                \"laplata\", \"manufacture\", \"mckeldinlib\", \"oakland\", \"physics\", \\\n",
    "                \"prince_frederick\", \"reckord_armory\", \"recreation\", \"regents_drive\", \"yahentamitsi\"]\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\", 0)\n",
    "    NUM_WORKERS = 16 # {2, 4, 8, 16, ...} Depends on the system's CPU\n",
    "    \n",
    "    PATH = './photos'\n",
    "    \n",
    "    BATCH_SIZE = 2**4\n",
    "    \n",
    "    TOTAL_STEPS = 2**15 # number of total steps to run\n",
    "    EVAL_STEPS = 2**10 # number of eval steps to run\n",
    "    EPOCHS = math.ceil(TOTAL_STEPS / EVAL_STEPS)\n",
    "    \n",
    "    LR = 0.001\n",
    "    WEIGHT_DECAY = 5e-4\n",
    "    MOMENTUM = 0.99\n",
    "    \n",
    "    WARM_UP = 0 # warmup epochs (unlabeled data based)\n",
    "    \n",
    "    EMA_DECAY = 0.999 # EMA decay rate\n",
    "    \n",
    "    # Hyper-param for wideresnet\n",
    "    WIDERESNET_DEPTH = 16\n",
    "    WIDERESNET_WIDEN_FACTOR=2\n",
    "    WIDERESNET_DROPOUT=1\n",
    "    \n",
    "    MU = 3 # coefficient of unlabeled batch size\n",
    "    LAMBDA_U = 1 # coefficient of unlabeled loss\n",
    "    \n",
    "    THRESHOLD = 0.95 # pseudo label threshold\n",
    "    T = 1 # pseudo label temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "class Config:\n",
    "    CLASSES = [\"art_sociology\", \"atlantic\", \"brendan_iribe_center\", \"denton\", \"elkton\", \\\n",
    "                \"ellicott\", \"esj\", \"farm_building\", \"hagerstown\", \"james_clark\", \\\n",
    "                \"laplata\", \"manufacture\", \"mckeldinlib\", \"oakland\", \"physics\", \\\n",
    "                \"prince_frederick\", \"reckord_armory\", \"recreation\", \"regents_drive\", \"yahentamitsi\"]\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\", 0)\n",
    "    NUM_WORKERS = 16 # {2, 4, 8, 16, ...} Depends on the system's CPU\n",
    "    \n",
    "    PATH = './photos'\n",
    "    \n",
    "    BATCH_SIZE = 2**4\n",
    "    \n",
    "    TOTAL_STEPS = 2**15 # number of total steps to run\n",
    "    EVAL_STEPS = 2**10 # number of eval steps to run\n",
    "    EPOCHS = math.ceil(TOTAL_STEPS / EVAL_STEPS)\n",
    "    \n",
    "    LR = 0.001\n",
    "    WEIGHT_DECAY = 5e-4\n",
    "    MOMENTUM = 0.99\n",
    "    \n",
    "    WARM_UP = 0 # warmup epochs (unlabeled data based)\n",
    "    \n",
    "    EMA_DECAY = 0.999 # EMA decay rate\n",
    "    \n",
    "    # Hyper-param for wideresnet\n",
    "    WIDERESNET_DEPTH = 16\n",
    "    WIDERESNET_WIDEN_FACTOR=2\n",
    "    WIDERESNET_DROPOUT=1\n",
    "    \n",
    "    MU = 3 # coefficient of unlabeled batch size\n",
    "    LAMBDA_U = 1 # coefficient of unlabeled loss\n",
    "    \n",
    "    THRESHOLD = 0.95 # pseudo label threshold\n",
    "    T = 1 # pseudo label temperature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
