Train Epoch: 1/  32. Iter: 1024/1024. LR: 0.0100. Data: 2.166s. Batch: 2.700s. Loss: 1.6902. Loss_x: 1.3173. Loss_u: 0.3729. Mask: 0.07. : 100%|██████████| 1024/1024 [46:03<00:00,  2.70s/it]  
Test Iter:  122/ 122. Data: 0.006s. Batch: 0.024s. Loss: 3.1769. top1: 23.74. top5: 55.01. : 100%|██████████| 122/122 [00:02<00:00, 41.76it/s]
Train Epoch: 2/  32. Iter: 1024/1024. LR: 0.0100. Data: 2.150s. Batch: 2.668s. Loss: 1.4553. Loss_x: 1.0561. Loss_u: 0.3993. Mask: 0.08. : 100%|██████████| 1024/1024 [45:29<00:00,  2.67s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 3.1187. top1: 26.63. top5: 58.93. : 100%|██████████| 122/122 [00:02<00:00, 43.30it/s]
Train Epoch: 3/  32. Iter: 1024/1024. LR: 0.0099. Data: 2.139s. Batch: 2.631s. Loss: 1.3850. Loss_x: 0.9744. Loss_u: 0.4106. Mask: 0.08. : 100%|██████████| 1024/1024 [44:51<00:00,  2.63s/it] 
Test Iter:  122/ 122. Data: 0.009s. Batch: 0.025s. Loss: 3.0072. top1: 27.30. top5: 61.40. : 100%|██████████| 122/122 [00:03<00:00, 40.29it/s]
Train Epoch: 4/  32. Iter: 1024/1024. LR: 0.0099. Data: 2.129s. Batch: 2.617s. Loss: 1.3513. Loss_x: 0.9097. Loss_u: 0.4416. Mask: 0.09. : 100%|██████████| 1024/1024 [44:36<00:00,  2.61s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.064s. Loss: 2.9466. top1: 28.59. top5: 64.34. : 100%|██████████| 122/122 [00:07<00:00, 15.47it/s]
Train Epoch: 5/  32. Iter: 1024/1024. LR: 0.0098. Data: 2.149s. Batch: 2.653s. Loss: 1.2974. Loss_x: 0.8496. Loss_u: 0.4478. Mask: 0.09. : 100%|██████████| 1024/1024 [45:08<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.063s. Loss: 2.9035. top1: 30.39. top5: 65.27. : 100%|██████████| 122/122 [00:07<00:00, 15.65it/s]
Train Epoch: 6/  32. Iter: 1024/1024. LR: 0.0097. Data: 2.163s. Batch: 2.702s. Loss: 1.3022. Loss_x: 0.8513. Loss_u: 0.4509. Mask: 0.09. : 100%|██████████| 1024/1024 [45:58<00:00,  2.69s/it] 
Test Iter:  122/ 122. Data: 0.045s. Batch: 0.080s. Loss: 2.9180. top1: 30.96. top5: 64.81. : 100%|██████████| 122/122 [00:09<00:00, 12.33it/s]
Train Epoch: 7/  32. Iter: 1024/1024. LR: 0.0096. Data: 2.112s. Batch: 2.625s. Loss: 1.3047. Loss_x: 0.8281. Loss_u: 0.4766. Mask: 0.09. : 100%|██████████| 1024/1024 [44:37<00:00,  2.62s/it] 
Test Iter:  122/ 122. Data: 0.033s. Batch: 0.068s. Loss: 2.9239. top1: 31.32. top5: 65.07. : 100%|██████████| 122/122 [00:08<00:00, 14.44it/s]
Train Epoch: 8/  32. Iter: 1024/1024. LR: 0.0094. Data: 2.174s. Batch: 2.691s. Loss: 1.2737. Loss_x: 0.8060. Loss_u: 0.4677. Mask: 0.09. : 100%|██████████| 1024/1024 [45:47<00:00,  2.68s/it] 
Test Iter:  122/ 122. Data: 0.033s. Batch: 0.067s. Loss: 2.8914. top1: 32.77. top5: 65.48. : 100%|██████████| 122/122 [00:08<00:00, 14.64it/s]
Train Epoch: 9/  32. Iter: 1024/1024. LR: 0.0093. Data: 2.197s. Batch: 2.714s. Loss: 1.2091. Loss_x: 0.7575. Loss_u: 0.4515. Mask: 0.09. : 100%|██████████| 1024/1024 [46:10<00:00,  2.71s/it] 
Test Iter:  122/ 122. Data: 0.034s. Batch: 0.073s. Loss: 2.8076. top1: 33.23. top5: 66.51. : 100%|██████████| 122/122 [00:08<00:00, 13.56it/s]
Train Epoch: 10/  32. Iter: 1024/1024. LR: 0.0091. Data: 2.187s. Batch: 2.699s. Loss: 1.2681. Loss_x: 0.7791. Loss_u: 0.4891. Mask: 0.09. : 100%|██████████| 1024/1024 [45:54<00:00,  2.69s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 2.7950. top1: 32.77. top5: 66.98. : 100%|██████████| 122/122 [00:02<00:00, 43.93it/s]
Train Epoch: 11/  32. Iter: 1024/1024. LR: 0.0089. Data: 2.251s. Batch: 2.773s. Loss: 1.1992. Loss_x: 0.7354. Loss_u: 0.4638. Mask: 0.09. : 100%|██████████| 1024/1024 [47:16<00:00,  2.77s/it] 
Test Iter:  122/ 122. Data: 0.008s. Batch: 0.024s. Loss: 2.7736. top1: 33.18. top5: 66.98. : 100%|██████████| 122/122 [00:03<00:00, 40.49it/s]
Train Epoch: 12/  32. Iter: 1024/1024. LR: 0.0087. Data: 2.216s. Batch: 2.728s. Loss: 1.1981. Loss_x: 0.7362. Loss_u: 0.4619. Mask: 0.09. : 100%|██████████| 1024/1024 [46:30<00:00,  2.73s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.024s. Loss: 2.7512. top1: 33.95. top5: 67.39. : 100%|██████████| 122/122 [00:02<00:00, 41.48it/s]
Train Epoch: 13/  32. Iter: 1024/1024. LR: 0.0085. Data: 2.198s. Batch: 2.714s. Loss: 1.1737. Loss_x: 0.7091. Loss_u: 0.4646. Mask: 0.09. : 100%|██████████| 1024/1024 [46:16<00:00,  2.71s/it] 
Test Iter:  122/ 122. Data: 0.008s. Batch: 0.025s. Loss: 2.6959. top1: 35.19. top5: 68.89. : 100%|██████████| 122/122 [00:03<00:00, 39.69it/s]
Train Epoch: 14/  32. Iter: 1024/1024. LR: 0.0082. Data: 2.189s. Batch: 2.705s. Loss: 1.1595. Loss_x: 0.6915. Loss_u: 0.4680. Mask: 0.09. : 100%|██████████| 1024/1024 [46:07<00:00,  2.70s/it] 
Test Iter:  122/ 122. Data: 0.032s. Batch: 0.067s. Loss: 2.6692. top1: 35.50. top5: 70.02. : 100%|██████████| 122/122 [00:08<00:00, 14.60it/s]
Train Epoch: 15/  32. Iter: 1024/1024. LR: 0.0080. Data: 2.175s. Batch: 2.699s. Loss: 1.1378. Loss_x: 0.6708. Loss_u: 0.4670. Mask: 0.09. : 100%|██████████| 1024/1024 [45:55<00:00,  2.69s/it] 
Test Iter:  122/ 122. Data: 0.032s. Batch: 0.068s. Loss: 2.6585. top1: 35.81. top5: 69.87. : 100%|██████████| 122/122 [00:08<00:00, 14.51it/s]
Train Epoch: 16/  32. Iter: 1024/1024. LR: 0.0077. Data: 2.192s. Batch: 2.713s. Loss: 1.1208. Loss_x: 0.6522. Loss_u: 0.4685. Mask: 0.09. : 100%|██████████| 1024/1024 [46:09<00:00,  2.70s/it] 
Test Iter:  122/ 122. Data: 0.032s. Batch: 0.066s. Loss: 2.6438. top1: 36.27. top5: 70.74. : 100%|██████████| 122/122 [00:08<00:00, 15.02it/s]
Train Epoch: 17/  32. Iter: 1024/1024. LR: 0.0075. Data: 2.165s. Batch: 2.665s. Loss: 1.1206. Loss_x: 0.6462. Loss_u: 0.4744. Mask: 0.09. : 100%|██████████| 1024/1024 [45:21<00:00,  2.66s/it] 
Test Iter:  122/ 122. Data: 0.031s. Batch: 0.066s. Loss: 2.6227. top1: 35.50. top5: 72.03. : 100%|██████████| 122/122 [00:08<00:00, 14.88it/s]
Train Epoch: 18/  32. Iter: 1024/1024. LR: 0.0072. Data: 2.218s. Batch: 2.757s. Loss: 1.0771. Loss_x: 0.6260. Loss_u: 0.4511. Mask: 0.09. : 100%|██████████| 1024/1024 [46:55<00:00,  2.75s/it] 
Test Iter:  122/ 122. Data: 0.034s. Batch: 0.071s. Loss: 2.5431. top1: 36.53. top5: 73.48. : 100%|██████████| 122/122 [00:08<00:00, 13.88it/s]
Train Epoch: 19/  32. Iter: 1024/1024. LR: 0.0069. Data: 2.162s. Batch: 2.662s. Loss: 1.0484. Loss_x: 0.6068. Loss_u: 0.4415. Mask: 0.09. : 100%|██████████| 1024/1024 [45:17<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.029s. Batch: 0.060s. Loss: 2.5320. top1: 36.58. top5: 73.99. : 100%|██████████| 122/122 [00:07<00:00, 16.36it/s]
Train Epoch: 20/  32. Iter: 1024/1024. LR: 0.0065. Data: 2.127s. Batch: 2.622s. Loss: 1.0242. Loss_x: 0.5777. Loss_u: 0.4466. Mask: 0.09. : 100%|██████████| 1024/1024 [44:37<00:00,  2.61s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.021s. Loss: 2.5228. top1: 36.58. top5: 74.36. : 100%|██████████| 122/122 [00:02<00:00, 46.33it/s]
Train Epoch: 21/  32. Iter: 1024/1024. LR: 0.0062. Data: 2.181s. Batch: 2.679s. Loss: 1.0191. Loss_x: 0.5772. Loss_u: 0.4419. Mask: 0.09. : 100%|██████████| 1024/1024 [45:41<00:00,  2.68s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 2.5020. top1: 36.74. top5: 74.46. : 100%|██████████| 122/122 [00:02<00:00, 43.14it/s]
Train Epoch: 22/  32. Iter: 1024/1024. LR: 0.0059. Data: 2.173s. Batch: 2.711s. Loss: 0.9809. Loss_x: 0.5364. Loss_u: 0.4446. Mask: 0.09. : 100%|██████████| 1024/1024 [46:13<00:00,  2.71s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.025s. Loss: 2.4463. top1: 38.08. top5: 74.92. : 100%|██████████| 122/122 [00:03<00:00, 40.20it/s]
Train Epoch: 23/  32. Iter: 1024/1024. LR: 0.0055. Data: 2.149s. Batch: 2.649s. Loss: 0.9947. Loss_x: 0.5454. Loss_u: 0.4493. Mask: 0.09. : 100%|██████████| 1024/1024 [45:10<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.029s. Batch: 0.063s. Loss: 2.4192. top1: 37.62. top5: 73.94. : 100%|██████████| 122/122 [00:07<00:00, 15.61it/s]
Train Epoch: 24/  32. Iter: 1024/1024. LR: 0.0051. Data: 2.160s. Batch: 2.652s. Loss: 0.9855. Loss_x: 0.5273. Loss_u: 0.4583. Mask: 0.09. : 100%|██████████| 1024/1024 [45:07<00:00,  2.64s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.063s. Loss: 2.4032. top1: 37.36. top5: 74.56. : 100%|██████████| 122/122 [00:07<00:00, 15.52it/s]
Train Epoch: 25/  32. Iter: 1024/1024. LR: 0.0048. Data: 2.126s. Batch: 2.615s. Loss: 0.9488. Loss_x: 0.5084. Loss_u: 0.4403. Mask: 0.09. : 100%|██████████| 1024/1024 [44:29<00:00,  2.61s/it] 
Test Iter:  122/ 122. Data: 0.033s. Batch: 0.067s. Loss: 2.4414. top1: 36.79. top5: 74.61. : 100%|██████████| 122/122 [00:08<00:00, 14.62it/s]
Train Epoch: 26/  32. Iter: 1024/1024. LR: 0.0044. Data: 2.166s. Batch: 2.666s. Loss: 0.9204. Loss_x: 0.4872. Loss_u: 0.4332. Mask: 0.09. : 100%|██████████| 1024/1024 [45:21<00:00,  2.66s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.065s. Loss: 2.4345. top1: 37.41. top5: 74.46. : 100%|██████████| 122/122 [00:08<00:00, 15.25it/s]
Train Epoch: 27/  32. Iter: 1024/1024. LR: 0.0040. Data: 2.147s. Batch: 2.639s. Loss: 0.9016. Loss_x: 0.4767. Loss_u: 0.4249. Mask: 0.09. : 100%|██████████| 1024/1024 [44:53<00:00,  2.63s/it] 
Test Iter:  122/ 122. Data: 0.032s. Batch: 0.068s. Loss: 2.4421. top1: 37.31. top5: 73.94. : 100%|██████████| 122/122 [00:08<00:00, 14.51it/s]
Train Epoch: 28/  32. Iter: 1024/1024. LR: 0.0036. Data: 2.178s. Batch: 2.674s. Loss: 0.8463. Loss_x: 0.4376. Loss_u: 0.4087. Mask: 0.08. : 100%|██████████| 1024/1024 [45:30<00:00,  2.67s/it] 
Test Iter:  122/ 122. Data: 0.034s. Batch: 0.072s. Loss: 2.4504. top1: 38.18. top5: 74.66. : 100%|██████████| 122/122 [00:08<00:00, 13.64it/s]
Train Epoch: 29/  32. Iter: 1024/1024. LR: 0.0032. Data: 2.171s. Batch: 2.665s. Loss: 0.8803. Loss_x: 0.4480. Loss_u: 0.4323. Mask: 0.09. : 100%|██████████| 1024/1024 [45:19<00:00,  2.66s/it] 
Test Iter:  122/ 122. Data: 0.031s. Batch: 0.066s. Loss: 2.4144. top1: 38.44. top5: 74.97. : 100%|██████████| 122/122 [00:08<00:00, 14.86it/s]
Train Epoch: 30/  32. Iter: 1024/1024. LR: 0.0028. Data: 2.172s. Batch: 2.666s. Loss: 0.8420. Loss_x: 0.4244. Loss_u: 0.4177. Mask: 0.09. : 100%|██████████| 1024/1024 [45:22<00:00,  2.66s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.021s. Loss: 2.3876. top1: 38.44. top5: 74.92. : 100%|██████████| 122/122 [00:02<00:00, 46.43it/s]
Train Epoch: 31/  32. Iter: 1024/1024. LR: 0.0024. Data: 2.229s. Batch: 2.732s. Loss: 0.7939. Loss_x: 0.4023. Loss_u: 0.3916. Mask: 0.08. : 100%|██████████| 1024/1024 [46:34<00:00,  2.73s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 2.4285. top1: 38.75. top5: 73.94. : 100%|██████████| 122/122 [00:02<00:00, 43.05it/s]
Train Epoch: 32/  32. Iter: 1024/1024. LR: 0.0020. Data: 2.198s. Batch: 2.730s. Loss: 0.7788. Loss_x: 0.3854. Loss_u: 0.3934. Mask: 0.08. : 100%|██████████| 1024/1024 [46:32<00:00,  2.73s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 2.4338. top1: 38.75. top5: 75.08. : 100%|██████████| 122/122 [00:02<00:00, 43.81it/s]
