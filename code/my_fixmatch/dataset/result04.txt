Train Epoch: 1/  32. Iter: 1024/1024. LR: 0.0100. Data: 2.194s. Batch: 2.721s. Loss: 1.2386. Loss_x: 0.7379. Loss_u: 0.5006. Mask: 0.10. : 100%|██████████| 1024/1024 [46:25<00:00,  2.72s/it]  
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.024s. Loss: 2.9212. top1: 27.19. top5: 61.76. : 100%|██████████| 122/122 [00:02<00:00, 41.01it/s]
Train Epoch: 2/  32. Iter: 1024/1024. LR: 0.0100. Data: 2.218s. Batch: 2.753s. Loss: 1.1162. Loss_x: 0.6391. Loss_u: 0.4770. Mask: 0.09. : 100%|██████████| 1024/1024 [46:55<00:00,  2.75s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.022s. Loss: 2.5076. top1: 32.97. top5: 70.28. : 100%|██████████| 122/122 [00:02<00:00, 44.39it/s]
Train Epoch: 3/  32. Iter: 1024/1024. LR: 0.0099. Data: 2.164s. Batch: 2.656s. Loss: 1.1195. Loss_x: 0.6264. Loss_u: 0.4931. Mask: 0.10. : 100%|██████████| 1024/1024 [45:16<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 2.4002. top1: 35.50. top5: 72.81. : 100%|██████████| 122/122 [00:02<00:00, 43.61it/s]
Train Epoch: 4/  32. Iter: 1024/1024. LR: 0.0099. Data: 2.113s. Batch: 2.607s. Loss: 1.1889. Loss_x: 0.6757. Loss_u: 0.5132. Mask: 0.10. : 100%|██████████| 1024/1024 [44:27<00:00,  2.60s/it] 
Test Iter:  122/ 122. Data: 0.029s. Batch: 0.063s. Loss: 2.3638. top1: 36.89. top5: 73.01. : 100%|██████████| 122/122 [00:07<00:00, 15.59it/s]
Train Epoch: 5/  32. Iter: 1024/1024. LR: 0.0098. Data: 2.119s. Batch: 2.612s. Loss: 1.1468. Loss_x: 0.6558. Loss_u: 0.4910. Mask: 0.10. : 100%|██████████| 1024/1024 [44:26<00:00,  2.60s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.063s. Loss: 2.3776. top1: 36.58. top5: 73.27. : 100%|██████████| 122/122 [00:07<00:00, 15.67it/s]
Train Epoch: 6/  32. Iter: 1024/1024. LR: 0.0097. Data: 2.139s. Batch: 2.630s. Loss: 1.1534. Loss_x: 0.6565. Loss_u: 0.4969. Mask: 0.10. : 100%|██████████| 1024/1024 [44:45<00:00,  2.62s/it] 
Test Iter:  122/ 122. Data: 0.028s. Batch: 0.063s. Loss: 2.3642. top1: 37.41. top5: 72.86. : 100%|██████████| 122/122 [00:07<00:00, 15.61it/s]
Train Epoch: 7/  32. Iter: 1024/1024. LR: 0.0096. Data: 2.158s. Batch: 2.653s. Loss: 1.1227. Loss_x: 0.6448. Loss_u: 0.4779. Mask: 0.10. : 100%|██████████| 1024/1024 [45:08<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.031s. Batch: 0.066s. Loss: 2.3348. top1: 37.67. top5: 73.74. : 100%|██████████| 122/122 [00:08<00:00, 14.82it/s]
Train Epoch: 8/  32. Iter: 1024/1024. LR: 0.0094. Data: 2.185s. Batch: 2.675s. Loss: 1.1083. Loss_x: 0.6154. Loss_u: 0.4929. Mask: 0.10. : 100%|██████████| 1024/1024 [45:31<00:00,  2.67s/it] 
Test Iter:  122/ 122. Data: 0.032s. Batch: 0.067s. Loss: 2.2967. top1: 38.13. top5: 75.08. : 100%|██████████| 122/122 [00:08<00:00, 14.67it/s]
Train Epoch: 9/  32. Iter: 1024/1024. LR: 0.0093. Data: 2.181s. Batch: 2.671s. Loss: 1.0927. Loss_x: 0.6244. Loss_u: 0.4683. Mask: 0.09. : 100%|██████████| 1024/1024 [45:26<00:00,  2.66s/it] 
Test Iter:  122/ 122. Data: 0.033s. Batch: 0.070s. Loss: 2.2722. top1: 38.39. top5: 74.66. : 100%|██████████| 122/122 [00:08<00:00, 14.14it/s]
Train Epoch: 10/  32. Iter: 1024/1024. LR: 0.0091. Data: 2.130s. Batch: 2.622s. Loss: 1.1056. Loss_x: 0.6120. Loss_u: 0.4936. Mask: 0.10. : 100%|██████████| 1024/1024 [44:36<00:00,  2.61s/it] 
Test Iter:  122/ 122. Data: 0.006s. Batch: 0.021s. Loss: 2.2730. top1: 37.25. top5: 74.97. : 100%|██████████| 122/122 [00:02<00:00, 46.60it/s]
Train Epoch: 11/  32. Iter: 1024/1024. LR: 0.0089. Data: 2.198s. Batch: 2.690s. Loss: 1.0999. Loss_x: 0.6173. Loss_u: 0.4826. Mask: 0.10. : 100%|██████████| 1024/1024 [45:51<00:00,  2.69s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.022s. Loss: 2.2752. top1: 36.64. top5: 76.16. : 100%|██████████| 122/122 [00:02<00:00, 44.82it/s]
Train Epoch: 12/  32. Iter: 1024/1024. LR: 0.0087. Data: 2.194s. Batch: 2.688s. Loss: 1.0797. Loss_x: 0.5973. Loss_u: 0.4824. Mask: 0.10. : 100%|██████████| 1024/1024 [45:49<00:00,  2.69s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 2.2574. top1: 36.53. top5: 76.16. : 100%|██████████| 122/122 [00:02<00:00, 43.73it/s]
Train Epoch: 13/  32. Iter: 1024/1024. LR: 0.0085. Data: 2.196s. Batch: 2.707s. Loss: 1.0508. Loss_x: 0.5856. Loss_u: 0.4652. Mask: 0.10. : 100%|██████████| 1024/1024 [46:09<00:00,  2.70s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.023s. Loss: 2.2623. top1: 37.51. top5: 75.80. : 100%|██████████| 122/122 [00:02<00:00, 42.29it/s]
Train Epoch: 14/  32. Iter: 1024/1024. LR: 0.0082. Data: 2.206s. Batch: 2.746s. Loss: 1.0566. Loss_x: 0.5776. Loss_u: 0.4790. Mask: 0.10. : 100%|██████████| 1024/1024 [46:48<00:00,  2.74s/it] 
Test Iter:  122/ 122. Data: 0.031s. Batch: 0.065s. Loss: 2.2818. top1: 37.82. top5: 74.77. : 100%|██████████| 122/122 [00:08<00:00, 15.06it/s]
Train Epoch: 15/  32. Iter: 1024/1024. LR: 0.0080. Data: 2.162s. Batch: 2.651s. Loss: 1.0506. Loss_x: 0.5710. Loss_u: 0.4796. Mask: 0.09. : 100%|██████████| 1024/1024 [45:06<00:00,  2.64s/it] 
Test Iter:  122/ 122. Data: 0.029s. Batch: 0.061s. Loss: 2.2724. top1: 37.51. top5: 75.59. : 100%|██████████| 122/122 [00:07<00:00, 16.21it/s]
Train Epoch: 16/  32. Iter: 1024/1024. LR: 0.0077. Data: 2.179s. Batch: 2.676s. Loss: 1.0607. Loss_x: 0.5815. Loss_u: 0.4792. Mask: 0.11. : 100%|██████████| 1024/1024 [45:32<00:00,  2.67s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.063s. Loss: 2.2600. top1: 39.27. top5: 75.95. : 100%|██████████| 122/122 [00:07<00:00, 15.51it/s]
Train Epoch: 17/  32. Iter: 1024/1024. LR: 0.0075. Data: 2.147s. Batch: 2.641s. Loss: 1.0126. Loss_x: 0.5496. Loss_u: 0.4630. Mask: 0.09. : 100%|██████████| 1024/1024 [44:56<00:00,  2.63s/it] 
Test Iter:  122/ 122. Data: 0.032s. Batch: 0.070s. Loss: 2.3042. top1: 38.54. top5: 74.97. : 100%|██████████| 122/122 [00:08<00:00, 14.13it/s]
Train Epoch: 18/  32. Iter: 1024/1024. LR: 0.0072. Data: 2.165s. Batch: 2.651s. Loss: 0.9681. Loss_x: 0.5220. Loss_u: 0.4461. Mask: 0.10. : 100%|██████████| 1024/1024 [45:06<00:00,  2.64s/it] 
Test Iter:  122/ 122. Data: 0.033s. Batch: 0.071s. Loss: 2.3067. top1: 38.96. top5: 74.77. : 100%|██████████| 122/122 [00:08<00:00, 13.87it/s]
Train Epoch: 19/  32. Iter: 1024/1024. LR: 0.0069. Data: 2.139s. Batch: 2.627s. Loss: 0.9492. Loss_x: 0.5010. Loss_u: 0.4483. Mask: 0.09. : 100%|██████████| 1024/1024 [44:40<00:00,  2.62s/it] 
Test Iter:  122/ 122. Data: 0.029s. Batch: 0.063s. Loss: 2.3045. top1: 38.85. top5: 75.34. : 100%|██████████| 122/122 [00:07<00:00, 15.56it/s]
Train Epoch: 20/  32. Iter: 1024/1024. LR: 0.0065. Data: 2.108s. Batch: 2.599s. Loss: 0.9967. Loss_x: 0.5308. Loss_u: 0.4659. Mask: 0.10. : 100%|██████████| 1024/1024 [44:13<00:00,  2.59s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.022s. Loss: 2.2854. top1: 38.80. top5: 75.34. : 100%|██████████| 122/122 [00:02<00:00, 45.08it/s]
Train Epoch: 21/  32. Iter: 1024/1024. LR: 0.0062. Data: 2.184s. Batch: 2.674s. Loss: 0.9310. Loss_x: 0.4924. Loss_u: 0.4387. Mask: 0.10. : 100%|██████████| 1024/1024 [45:35<00:00,  2.67s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.022s. Loss: 2.3508. top1: 38.91. top5: 74.87. : 100%|██████████| 122/122 [00:02<00:00, 44.33it/s]
Train Epoch: 22/  32. Iter: 1024/1024. LR: 0.0059. Data: 2.178s. Batch: 2.671s. Loss: 0.9340. Loss_x: 0.4855. Loss_u: 0.4485. Mask: 0.09. : 100%|██████████| 1024/1024 [45:32<00:00,  2.67s/it] 
Test Iter:  122/ 122. Data: 0.008s. Batch: 0.023s. Loss: 2.3125. top1: 40.25. top5: 75.59. : 100%|██████████| 122/122 [00:02<00:00, 42.99it/s]
Train Epoch: 23/  32. Iter: 1024/1024. LR: 0.0055. Data: 2.136s. Batch: 2.641s. Loss: 0.9507. Loss_x: 0.4927. Loss_u: 0.4580. Mask: 0.09. : 100%|██████████| 1024/1024 [45:01<00:00,  2.64s/it] 
Test Iter:  122/ 122. Data: 0.031s. Batch: 0.064s. Loss: 2.2866. top1: 40.82. top5: 76.63. : 100%|██████████| 122/122 [00:07<00:00, 15.44it/s]
Train Epoch: 24/  32. Iter: 1024/1024. LR: 0.0051. Data: 2.171s. Batch: 2.661s. Loss: 0.8982. Loss_x: 0.4738. Loss_u: 0.4244. Mask: 0.09. : 100%|██████████| 1024/1024 [45:16<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.031s. Batch: 0.067s. Loss: 2.3002. top1: 40.45. top5: 75.44. : 100%|██████████| 122/122 [00:08<00:00, 14.63it/s]
Train Epoch: 25/  32. Iter: 1024/1024. LR: 0.0048. Data: 2.161s. Batch: 2.653s. Loss: 0.9185. Loss_x: 0.4703. Loss_u: 0.4482. Mask: 0.10. : 100%|██████████| 1024/1024 [45:07<00:00,  2.64s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.063s. Loss: 2.3134. top1: 39.89. top5: 75.39. : 100%|██████████| 122/122 [00:07<00:00, 15.46it/s]
Train Epoch: 26/  32. Iter: 1024/1024. LR: 0.0044. Data: 2.163s. Batch: 2.655s. Loss: 0.8646. Loss_x: 0.4296. Loss_u: 0.4350. Mask: 0.10. : 100%|██████████| 1024/1024 [45:11<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.030s. Batch: 0.064s. Loss: 2.3246. top1: 39.53. top5: 75.80. : 100%|██████████| 122/122 [00:07<00:00, 15.36it/s]
Train Epoch: 27/  32. Iter: 1024/1024. LR: 0.0040. Data: 2.157s. Batch: 2.648s. Loss: 0.8552. Loss_x: 0.4431. Loss_u: 0.4121. Mask: 0.15. : 100%|██████████| 1024/1024 [45:03<00:00,  2.64s/it] 
Test Iter:  122/ 122. Data: 0.033s. Batch: 0.066s. Loss: 2.3267. top1: 39.11. top5: 76.32. : 100%|██████████| 122/122 [00:08<00:00, 14.87it/s]
Train Epoch: 28/  32. Iter: 1024/1024. LR: 0.0036. Data: 2.188s. Batch: 2.682s. Loss: 0.8316. Loss_x: 0.5321. Loss_u: 0.2995. Mask: 0.51. : 100%|██████████| 1024/1024 [45:38<00:00,  2.67s/it] 
Test Iter:  122/ 122. Data: 0.033s. Batch: 0.071s. Loss: 2.7211. top1: 27.71. top5: 76.57. : 100%|██████████| 122/122 [00:08<00:00, 13.85it/s]
Train Epoch: 29/  32. Iter: 1024/1024. LR: 0.0032. Data: 2.173s. Batch: 2.662s. Loss: 0.7132. Loss_x: 0.4931. Loss_u: 0.2201. Mask: 0.69. : 100%|██████████| 1024/1024 [45:16<00:00,  2.65s/it] 
Test Iter:  122/ 122. Data: 0.029s. Batch: 0.062s. Loss: 3.1456. top1: 21.83. top5: 74.56. : 100%|██████████| 122/122 [00:07<00:00, 15.86it/s]
Train Epoch: 30/  32. Iter: 1024/1024. LR: 0.0028. Data: 2.140s. Batch: 2.638s. Loss: 0.6422. Loss_x: 0.4468. Loss_u: 0.1954. Mask: 0.76. : 100%|██████████| 1024/1024 [44:53<00:00,  2.63s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.021s. Loss: 3.4638. top1: 19.81. top5: 72.14. : 100%|██████████| 122/122 [00:02<00:00, 46.25it/s]
Train Epoch: 31/  32. Iter: 1024/1024. LR: 0.0024. Data: 2.172s. Batch: 2.665s. Loss: 0.5596. Loss_x: 0.3973. Loss_u: 0.1623. Mask: 0.80. : 100%|██████████| 1024/1024 [45:26<00:00,  2.66s/it] 
Test Iter:  122/ 122. Data: 0.007s. Batch: 0.022s. Loss: 3.6405. top1: 19.45. top5: 70.33. : 100%|██████████| 122/122 [00:02<00:00, 45.88it/s]
Train Epoch: 32/  32. Iter: 1024/1024. LR: 0.0020. Data: 2.194s. Batch: 2.687s. Loss: 0.5778. Loss_x: 0.4028. Loss_u: 0.1750. Mask: 0.79. : 100%|██████████| 1024/1024 [45:49<00:00,  2.68s/it] 
Test Iter:  122/ 122. Data: 0.008s. Batch: 0.023s. Loss: 3.7339. top1: 20.07. top5: 69.56. : 100%|██████████| 122/122 [00:02<00:00, 43.23it/s]
